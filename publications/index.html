<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Roman Ibrahimov


  | Publications

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>🤖</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://roman-ibr.github.io/">
       Roman Ibrahimov
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">


          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              Home
              
            </a>
          </li>



          <!-- CV/Resume -->
          <li class="nav-item ">
            <a class="nav-link" href="/assets/pdf/roman_cv.pdf">
              CV   
            </a>
          </li>




                          <!-- Projects -->
          <li class="nav-item active">
            <a class="nav-link" href="/projects/">
              Projects
              
            </a>
          </li>




                          <!-- Publications -->
          <li class="nav-item active">
            <a class="nav-link" href="/publications/">
              Publications
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>

                          <!-- Teaching -->
          <li class="nav-item ">
            <a class="nav-link" href="/teaching/">
              Teaching
              
            </a>
          </li>










                  <!-- Services -->
<!--           <li class="nav-item ">
            <a class="nav-link" href="/services/">
              Services
              
            </a>
          </li> -->

                          <!-- Photography -->
          <li class="nav-item ">
            <a class="nav-link" href="https://www.instagram.com/roman_ibrahimov_/" target="_blank" rel="noopener noreferrer">
              Photography   
            </a>
          </li>
          <li class="nav-item ">
            <a class="nav-link" href="/contact/">
              Contact
              
            </a>
          </li>

          
          <!-- Blog -->
<!--           <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li> -->
          
          <!-- Other pages /title-->
<!--            
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/contact/">
                Contact
                
              </a>
          </li>
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                Publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/services/">
                Services
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching Experience
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
           -->
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Publications</h1>
    <p class="post-description">Please, visit my <a href="https://scholar.google.com/citations?user=OUct8qMAAAAJ&amp;hl=en&amp;oi=ao" target="_blank" rel="noopener noreferrer">[Google Scholar]</a> page to see the full list.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2022</h2>
  <ol class="bibliography"><li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ASME IDETC/CIE</abbr>
    
  
  </div>

  <div id="behjat2022" class="col-sm-8">
    
      <div class="title">A Computational Framework for the Evaluation of Resilience in Deep Space Habitat Systems </div>
      <div class="author">
        
      </div>

      <div class="periodical">
      
        <em>ASME IDETC/CIE</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Resilience is a vital consideration for designing and operating a deep space habitat system. The numerous hazards that may affect a deep space habitat and its crew during its lifecycle need to be considered early in the design. Trade-off studies are the typical method used to assess the cost and value of different design choices. Here we develop a modular dynamic computational framework intended for rapid simulation and evaluation of the resilience of different system configurations. The framework uses a system-level phenomeno-logical Markov model of the habitat systems, enabling us to assess multiple habitat configurations and evaluate their performance in the presence of several hazards and user-defined control policies. System fault detection and repairs are modeled. External disturbances, including meteorites impact, temperature fluctuations, and dust, are modeled based on the lunar environment, envisioning a deep space habitat design. We use a reflexive health management subsystem that prioritizes recovery actions based on the robotic agent’s availability to close the loop. In addition to performance, a resilience metric is included to quantify the system’s resilience over the design lifecycle. We illustrate the use of the framework for supporting early-stage design decisions of a habitat system. Our case study focuses on designing the power generation system considering cost and energy efficiency.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SIGGRAPH ASIA</abbr>
    
  
  </div>

  <div id="tsykunov2021dronestick" class="col-sm-8">
    
      <div class="title">DroneStick: Flying Joystick as a Novel Type of Interface</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Tsykunov, Evgeny,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fedoseev, Aleksey,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Dorzhieva, Ekaterina,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Agishev, Ruslan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ibrahimov, Roman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vasquez, Derek,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Labazanova, Luiza,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsetserukou, Dzmitry
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ACM SIGGRAPH Asia</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/DroneStick.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>DroneStick is a novel hands-free method for smooth interaction between a human and a robotic system via one of its agents, without training and any additional handheld or wearable device or infrastructure. A flying joystick (DroneStick), being a part of a multi-robot system, is composed of a flying drone and coiled wire with a vibration motor. By pulling on the coiled wire, the operator commands certain motions of the follower robotic system. The DroneStick system does not require the user to carry any equipment before or after performing the required interaction. DroneStick provides useful feedback to the operator in the form of force transferred through the wire, translation/rotation of the flying joystick, and motor vibrations at the fingertips. Feedback allows users to interact with different forms of robotic systems intuitively. A potential application can enhance an automated ‘last mile’ delivery when a recipient needs to guide a delivery drone/robot gently to a spot where a parcel has to be dropped.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SIGGRAPH</abbr>
    
  
  </div>

  <div id="karmanova2021swarmplay" class="col-sm-8">
    
      <div class="title">SwarmPlay: A Swarm of Nano-Quadcopters Playing Tic-tac-toe Board Game against a Human</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Karmanova, Ekaterina,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Serpiva, Valerii,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Perminov, Stepan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ibrahimov, Roman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fedoseev, Aleksey,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsetserukou, Dzmitry
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ACM SIGGRAPH Emerging Technologies</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/SwarmPlay.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We present a new paradigm of games, ie SwarmPlay, where each playing component is presented by an individual drone that has its own mobility and swarm intelligence to win against a human player. The motivation behind the research is to make the games with machines tangible and interactive. Although some research on the robotic players for board games already exists, eg, chess, the SwarmPlay technology has the potential to offer much more engagement and interaction with a human as it proposes a multi-agent swarm instead of a single interactive robot. The proposed system consists of a robotic swarm, a workstation, a computer vision (CV), and Game Theory-based algorithms. A novel game algorithm was developed to provide a natural game experience to the user. The preliminary user study revealed that participants were highly engaged in the game with drones (69% put a maximum score on the Likert scale) and found it less artificial compared to the regular computer-based systems (77% put maximum score). The affection of the user’s game perception from its outcome was analyzed and put under discussion. User study revealed that SwarmPlay has the potential to be implemented in a wider range of games, significantly improving human-drone interactivity</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE HAPTICS</abbr>
    
  
  </div>

  <div id="tsykunov2020swarmcloak" class="col-sm-8">
    
      <div class="title">SwarmCloak: Landing of Two Micro-Quadrotors on Human Hands Using Wearable Tactile Interface Driven by Light Intensity</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Tsykunov, Evgeny,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Agishev, Ruslan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ibrahimov, Roman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Moriyama, Taha,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Labazanova, Luiza,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kajimoto, Hiroyuki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsetserukou, Dzmitry
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2020 IEEE Haptics Symposium (HAPTICS)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/SwarmCloak.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>For the human operator, it is often easier and faster to catch a small size quadrotor right in the midair instead of landing it on a surface. However, interaction strategies for such cases have not yet been considered properly, especially when more than one drone has to be landed at the same time. In this paper, we propose a novel interaction strategy to land multiple robots on the human hands using vibrotactile feedback. We developed a wearable tactile display that is activated by the intensity of light emitted from an LED ring on the bottom of the quadcopter. We conducted experiments, where participants were asked to adjust the position of the palm to land one or two vertically-descending drones with different landing speeds, by having only visual feedback, only tactile feedback or visual-tactile feedback. We conducted statistical analysis of the drone landing positions, landing pad and human head trajectories. Two-way ANOVA showed a statistically significant difference between the feedback conditions. Experimental analysis proved that with an increasing number of drones, tactile feedback plays a more important role in accurate hand positioning and operator’s convenience. The most precise landing of one and two drones was achieved with the combination of tactile and visual feedback.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE RO-MAN</abbr>
    
  
  </div>

  <div id="ibrahimov2020dronelight" class="col-sm-8">
    
      <div class="title">DroneLight: Drone Draws in the Air using Long Exposure Light Painting and ML</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ibrahimov, Roman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zherdev, Nikolay,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsetserukou, Dzmitry
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2020 29th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/DroneLight.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose a novel human-drone interaction paradigm where a user directly interacts with a drone to light-paint predefined patterns or letters through hand gestures. The user wears a glove which is equipped with an IMU sensor to draw letters or patterns in the midair. The developed ML algorithm detects the drawn pattern and the drone light-paints each pattern in midair in the real time. The proposed classification model correctly predicts all of the input gestures. The DroneLight system can be applied in drone shows, advertisements, distant communication through text or pattern, rescue, and etc. To our knowledge, it would be the world’s first human-centric robotic system that people can use to send messages based on light-painting over distant locations (drone-based instant messaging). Another unique application of the system would be the development of vision-driven rescue system that reads light-painting by person who is in distress
  and triggers rescue alarm.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE ICAR</abbr>
    
  
  </div>

  <div id="yashin2019aerovr" class="col-sm-8">
    
      <div class="title">AeroVR: Virtual reality-based teleoperation with tactile feedback for aerial manipulation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Yashin, Grigoriy A,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Trinitatova, Daria,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Agishev, Ruslan T,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ibrahimov, Roman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsetserukou, Dzmitry
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2019 19th International Conference on Advanced Robotics (ICAR)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/AeroVR.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>— Drone application for aerial manipulation is tested in such areas as industrial maintenance, supporting the rescuers in emergencies, and e-commerce. Most of such applications require teleoperation. The operator receives visual feedback from the camera installed on a robot arm or drone. As aerial manipulation requires delicate and precise motion of robot arm, the camera data delay, narrow field of view, and blurred image caused by drone dynamics can lead the UAV to crash. The paper focuses on the development of a novel teleoperation system for aerial manipulation using Virtual Reality (VR). The controlled system consists of UAV with a 4-DoF robotic arm and embedded sensors. VR application presents the digital twin of drone and remote environment to the user through a headmounted display (HMD). The operator controls the position of the robotic arm and gripper with VR trackers worn on the arm and tracking glove with vibrotactile feedback. Control data is translated directly from VR to the real robot in realtime. The experimental results showed a stable and robust teleoperation mediated by the VR scene. The proposed system can considerably improve the quality of aerial manipulations.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SIGGRAPH ASIA</abbr>
    
  
  </div>

  <div id="tsykunov2019swarmcloak" class="col-sm-8">
    
      <div class="title">SwarmCloak: Landing of a Swarm of Nano-Quadrotors on Human Arms</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Tsykunov, Evgeny,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Agishev, Ruslan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ibrahimov, Roman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Labazanova, Luiza,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Moriyama, Taha,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kajimoto, Hiroyuki,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsetserukou, Dzmitry
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/SwarmCloak_Siggraph.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose a novel system SwarmCloak for landing of a fleet of four flying robots on the human arms using light-sensitive landing pads with vibrotactile feedback. We developed two types of wearable tactile displays with vibromotors which are activated by the light emitted from the LED array at the bottom of quadcopters. In a user study, participants were asked to adjust the position of the arms to land up to two drones, having only visual feedback, only tactile feedback or visual-tactile feedback. The experiment revealed that when the number of drones increases, tactile feedback plays a more important role in accurate landing and operator’s convenience. An important finding is that the best landing performance is achieved with the combination of tactile and visual feedback. The proposed technology could have a strong impact on the human-swarm interaction, providing a new level of intuitiveness and engagement into the swarm deployment just right from the skin surface.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ACM VRST</abbr>
    
  
  </div>

  <div id="tsykunov2019slingdrone" class="col-sm-8">
    
      <div class="title">SlingDrone: Mixed Reality System for Pointing and Interaction Using a Single Drone</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Tsykunov, Evgeny,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ibrahimov, Roman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vasquez, Derek,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsetserukou, Dzmitry
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 25th ACM Symposium on Virtual Reality Software and Technology</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/SlingDrone.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We propose SlingDrone, a novel Mixed Reality interaction paradigm that utilizes a micro-quadrotor as both pointing controller and interactive robot with a slingshot motion type. The drone attempts to hover at a given position while the human pulls it in desired direction using a hand grip and a leash. Based on the displacement, a virtual trajectory is defined. To allow for intuitive and simple control, we use virtual reality (VR) technology to trace the path of the drone based on the displacement input. The user receives force feedback propagated through the leash. Force feedback from SlingDrone coupled with visualized trajectory in VR creates an intuitive and user friendly pointing device. When the drone is released, it follows the trajectory that was shown in VR. Onboard payload (e.g. magnetic gripper) can perform various scenarios for real interaction with the surroundings, e.g. manipulation or sensing. Unlike HTC Vive controller, SlingDrone does not require handheld devices, thus it can be used as a standalone pointing technology in VR.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE RO-MAN</abbr>
    
  
  </div>

  <div id="ibrahimov2019dronepick" class="col-sm-8">
    
      <div class="title">DronePick: Object picking and delivery teleoperation with the drone controlled by a wearable tactile display</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ibrahimov, Roman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tsykunov, Evgeny,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Shirokun, Vladimir,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Somov, Andrey,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsetserukou, Dzmitry
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/DronePick.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>We report on the teleoperation system DronePick which provides remote object picking and delivery by a humancontrolled quadcopter. The main novelty of the proposed system is that the human user continuously gets the visual and haptic feedback for accurate teleoperation. DronePick consists of a quadcopter equipped with a magnetic grabber, a tactile glove with finger motion tracking sensor, hand tracking system, and the Virtual Reality (VR) application. The human operator teleoperates the quadcopter by changing the position of the hand. The proposed vibrotactile patterns representing the location of the remote object relative to the quadcopter are delivered to the glove. It helps the operator to determine when the quadcopter is right above the object. When the “pick” command is sent by clasping the hand in the glove, the quadcopter decreases its altitude and the magnetic grabber attaches the target object. The whole scenario is in parallel simulated in VR. The air flow from the quadcopter and the relative positions of VR objects help the operator to determine the exact position of the delivered object to be picked. The experiments showed that the vibrotactile patterns were recognized by the users at the high recognition rates: the average 99% recognition rate and the average 2.36s recognition time. The real-life implementation of DronePick featuring object picking and delivering to the human was developed and tested.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IEEE ToH</abbr>
    
  
  </div>

  <div id="tsykunov2019swarmtouch" class="col-sm-8">
    
      <div class="title">SwarmTouch: Guiding a swarm of micro-quadrotors with impedance control using a wearable tactile interface</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Tsykunov, Evgeny,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Agishev, Ruslan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ibrahimov, Roman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Labazanova, Luiza,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tleugazy, Akerke,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Tsetserukou, Dzmitry
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>IEEE transactions on haptics</em>
      
      
        2019
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/SwarmTouch.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>To achieve a smooth and safe guiding of a drone formation by a human operator, we propose a novel interaction strategy for a human-swarm communication which combines impedance control and vibrotactile feedback. The presented approach takes into account the human hand velocity and changes the formation shape and dynamics accordingly using impedance interlinks simulated between quadrotors, which helps to achieve a natural swarm behavior. Several tactile patterns representing static and dynamic parameters of the swarm are proposed. The user feels the state of the swarm at the fingertips and receives valuable information to improve the controllability of the complex formation. A user study revealed the patterns with high recognition rates. A flight experiment demonstrated the possibility to accurately navigate the formation in a cluttered environment using only tactile feedback. Subjects stated that tactile sensation allows guiding the drone formation through obstacles and makes the human-swarm communication more interactive. The proposed technology can potentially have a strong impact on the human-swarm interaction, providing a higher level of awareness during the swarm navigation.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2023 Roman  Ibrahimov.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
